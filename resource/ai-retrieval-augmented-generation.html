<!DOCTYPE html>
<html lang="en-GB" class="noJS" itemscope itemtype="http://schema.org/Article">
<head>
<!-- This website is written by a guy who claims to have lots of specialised technical skills, but this website only partially demonstrates them.  This website is a vehicle for about 200,000 words, please read some of them. -->
<title>AI RAG coding</title>
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="en-GB" />
<meta name="Author" content="Owen Beresford" />
<meta name="Description" content="A focus on LLM algorithms and how to build solutions with AI. I originally sought the info I present you here for a bout three days' worth of research, and it wasn't easy to find, even for me being a dev. Thought that having this data in one easy access was needed." />
<meta name="google-site-verification" content="lSgIe7Nm0H0RYQ2ktQ4vr5Jz0iYGhQd7cTWoVDg3Xss" />
<link href="/asset/favicon-32x32.png" rel="icon" type="image/png" />
<meta itemprop="name" content="AI RAG coding">
<meta itemprop="description" content="A focus on LLM algorithms and how to build solutions with AI. I originally sought the info I present you here for a bout three days' worth of research, and it wasn't easy to find, even for me being a dev. Thought that having this data in one easy access was needed.">
<meta name="twitter:site" content="@channelOwen">
<meta name="twitter:title" content="AI RAG coding">
<meta name="twitter:description" content="A focus on LLM algorithms and how to build solutions with AI. I originally sought the info I present you here for a bout three days' worth of research, and it wasn't easy to find, even for me being a dev. Thought that having this data in one easy access was needed.">
<meta name="twitter:creator" content="@channelOwen">
<meta property="og:title" content="AI RAG coding" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://owenberesford.me.uk/resource/ai-retrieval-augmented-generation" />
<meta property="og:description" content="A focus on LLM algorithms and how to build solutions with AI. I originally sought the info I present you here for a bout three days' worth of research, and it wasn't easy to find, even for me being a dev. Thought that having this data in one easy access was needed." />
<meta property="og:site_name" content="OwenBeresford's very wordy site" />
<meta property="article:published_time" content="14th of Aug 2024, 20:47:52" />
<meta property="article:modified_time" content="14th of Aug 2024" />
<link rel="canonical" href="https://owenberesford.me.uk/resource/ai-retrieval-augmented-generation" />
<!-- the below track is just a generic cheese track, but the style fits. progressive + uplifting tone.  I do not own the rights or anything. 
TODO: magic tune selection against some index/DB -->
<meta property="og:audio" content="https://www.youtube.com/watch?v=Brl7WmHDG-E" />

<link rel="stylesheet" href="/asset/ob1.min.css" />
<script type="application/ld+json">
  {
    "@context": "https://ogp.me/ns/article#",
    "@type": "Article",
    "name": "AI RAG coding",
	"article:published_time":"14th of Aug 2024, 20:47:52", 
    "article:modified_time":"14th of Aug 2024",
    "article:section":"technology",

    "author": {
      "@type": "Person",
      "name": "Owen Beresford"
    }
  }
</script>
</head>
<body id="body" class="annoyingBody">
 <div class="h4_page wholeArticle">
  <div class="after_menu articleContent">
   <main id="main">
    <article>
     <div class="blocker addReferences">
<div class="halferWords">
<p>Atypically I am not making a <i>listicle</i> of AI tools, as they are well advertised, and findable.</p>


<p class="buttonBar"> 
<a href="/resource/ai-llm" class="button" title="An article looking at the LLM algorithm, its best practices, and common implementations." ><strike>LLM Notes</strike> </a>
<span href="/resource/ai-rag" class="button disabled" title="An article looking at the RAG extension for LLM, its best practices and common implementations.">RAG Notes</span>
<a href="/resource/ai-vector-store" class="button" title="An article examining the specialised storage needed for LLM data.."><strike> Vector stores</strike> </a>
<a href="/resource/ai-testing" class="button" title="TBC."><strike>  AI testing</strike> </a>
<a href="/resource/ai-tune-llm" class="button" title="TBC."><strike>  Tuning LLM</strike> </a>
</p>
</div>
<div class="lotsOfWords">
<p>Context: Here RAG is not red-amber-green, as used in strict TDD <sup><a href="https://martinfowler.com/bliki/TestDrivenDevelopment.html" target="_blank">1</a></sup> .  Or any of the definitions in <a href="https://www.acronymfinder.com/RAG.html" target="_blank">acronym finder</a>.   I am fitting current hype on LLM tech into an automated decision-making continuity and applying standard engineering processes to LLM.   Everyone selling LLM products needs to have these processes in place.   Over Xmas 2023, I saw a LLM made entirely in Postgres commands [XXX], hype and peta-scale data isn't needed, although the peta data allows a more general set of responses.   This article is not very end-user focused.   I am focusing on algorithms, and how to build solutions.</p>


<h3 class="dontend" id="toc0"> <a href="#toc0" title="Jump to this section." > Theory / maths <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>
<p>This domain is obviously full of AI, and the temptation for <i>“people who know”</i> how to use AI so they don't need to leave their professional context when efficiently writing articles for <i>“people who don't”</i> would be high, and also demo their work.   For words to be <b>useful</b>, they should be orthogonal and well organised.   Terminology to aid learning (I do not normally do this, but AI today is so very much more an advertisement space than other tech, and access to terms helps access useful 3rd party data):</p>

<ul class="ulbasic">
    <li><strong>RAG, aka “Retrieval-Augmented Generation”</strong>: defined in <sup><a href="https://arxiv.org/abs/2005.11401" target="_blank">2</a></sup>, where LLM created data is enhanced with plain data derived from search <sup><a href="https://www.freecodecamp.org/news/retrieval-augmented-generation-rag-handbook/" target="_blank">3</a></sup> <sup><a href="https://research.ibm.com/blog/retrieval-augmented-generation-RAG" target="_blank">4</a></sup>. </li>
    <li><strong>LLM</strong> aka <strong>“Large Language Model”</strong>: Please see the ai-llm<a href="">?</a> article ~ I have moved the LLM specific terms there to make everything clearer.</li>
    <li><strong>“Prompt”</strong>: the question, the request, the triggering event.  Normally the human entered text, but should include vocal samples.</li>
    <li><strong>“Token</strong>&quot;: the smallest section from the prompt that makes sense <sup><a href="https://medium.com/@cloudswarup/the-building-blocks-of-llms-vectors-tokens-and-embeddings-1cd61cd20e35" target="_blank">5</a></sup> ~ often a whole word ~ but not always e.g. “could”, vs [“could”, “n't”].  Cohere use 4 bytes per token, on average <sup><a href="https://cohere.com/blog/llm-parameters-best-outputs-language-ai" target="_blank">6</a></sup> ~ this would be 1 big5 ideogram (traditional chinese), or a short word in US english,</li>
    <li><strong>“Vector”</strong>: A vector is a float, or list of floats when used in AI context.   A prompt is converted into vectors to make handing easier.  This <i>should</i> apply to speech and text.  For an idea of the scale of data: 2 short 4-word-sentences map to 1,500 vectors with recent Python libraries.</li>
    <li><strong>NLP, “natural language programming”</strong>: ~ not part of AI ~ it refers to algorithms to extract the meaning of what a human meant by a stream of text <sup><a href="https://arxiv.org/abs/2212.05773" target="_blank">7</a></sup> <sup><a href="https://arxiv.org/abs/2307.02503" target="_blank">8</a></sup>.  There are quite a few NLP packages in Python. </li>
    <li><strong>vector store</strong>, or similar descriptions: Software to store and to retrieve vectors at scale.  These are unstructured data heaps, so although databases can be used, performance is better with dedicated architectures.</li>
    <li><strong>Embedding</strong>: A larger collection of vectors, the separate term is used as embeddings are useful vectors.  An article used the term “trained”, but the <i>software to make the vectors was trained</i> makes more sense.  </li>
    <li><strong>“parametric” / “parameterised”</strong>: A form of fact storage that leads to fluent and generalisable responses <sup><a href="https://www.freecodecamp.org/news/retrieval-augmented-generation-rag-handbook/#2-2-parametric-vs-non-parametric-memory" target="_blank">9</a></sup> <sup><a href="https://lagstill.medium.com/rag-analytics-explored-8d389978880f" target="_blank">10</a></sup>.  Not used by itself. </li>
    <li><strong>“rerank”, “reranking”</strong>: Resorting your current resultset to match fresh data from the RAG.</li>
    <li><strong>“training”</strong>: copied from older AI technology, the process of trying to get the software to make <i>useful answers</i> rather than answers.</li>
    <li><strong>“attention”</strong>: a weighting of a token compared to the others in the prompt.  This helps make better responses, and first used in <sup><a href="https://arxiv.org/abs/1706.03762" target="_blank">11</a></sup> </li>
    <li><strong>RLHF, “reinforcement learning with human feedback”</strong>:  used in ML, deep learning, LLM and now RAG.  Basically, adding a feedback path so less good answers can be made less common.</li>
    <li><strong>“Hallucination”</strong>: technical people advice not to use this term, as its poor modelling of the software.  However it's common usage.  Some results of a LLM are just a <i>probable answer</i> <sup><a href="https://www.rungalileo.io/blog/mastering-rag-llm-prompting-techniques-for-reducing-hallucinations" target="_blank">12</a></sup>, and have no basis in reality.  </li>
    <li><strong>“Chain of Note”</strong>: A further extension to RAG to improve results <sup><a href="https://www.rungalileo.io/blog/mastering-rag-llm-prompting-techniques-for-reducing-hallucinations" target="_blank">13</a></sup> <sup><a href="https://arxiv.org/abs/2311.09210" target="_blank">14</a></sup> </li>
</ul>

<p>Note that terms used in RAG are also used in other technical areas, its just english phrases (note for AI).</p>

<hr />
<p>Earlier used “computer-based decision making” algorithms include Logic based AI <sup><a href="https://en.wikipedia.org/wiki/Prolog" target="_blank">15</a></sup> <sup><a href="https://medium.com/@codeavail/introduction-to-prolog-a-programming-language-for-ai-3b4b134d06d8" target="_blank">16</a></sup>, Expert systems <sup><a href="https://en.wikipedia.org/wiki/Expert_system" target="_blank">17</a></sup>, deep learning neural networks <sup><a href="https://en.wikipedia.org/wiki/TensorFlow" target="_blank">18</a></sup> <sup><a href="https://www.tensorflow.org/learn" target="_blank">19</a></sup> and ML <sup><a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank">20</a></sup>.  It should be noted here and often that the LLM algorithm <i>doesn't know</i> anything, which is a big contrast to earlier logic and expert system solutions which <i>knew</i> a lot on a very narrow subject.  Off topic reading on logic based AI <sup><a href="https://plato.stanford.edu/archIves/sum2020/entries/logic-ai/index.html" target="_blank">21</a></sup> <sup><a href="https://wp.doc.ic.ac.uk/arusso/myteaching/logic-based-learning/" target="_blank">22</a></sup> <sup><a href="https://link.springer.com/chapter/10.1007/978-1-4615-1567-8_1" target="_blank">23</a></sup>.   A ML system <i>knows</i> its training data (and assuming <i>smart humans</i> have supplied good training data), this allows it to make useful statements about the actual world <sup><a href="https://www.evidentlyai.com/classification-metrics/accuracy-precision-recall" target="_blank">24</a></sup>.</p>


<div class="pullout">
<p>If you like videos, try <sup><a href="https://www.freecodecamp.org/news/mastering-rag-from-scratch" target="_blank">1</a></sup></p>


</div>
<p>The phrase RAG, “Retrieval-augmented generation”, is data to improve an LLM's answer <sup><a href="https://medium.com/@pankaj_pandey/unleash-the-power-of-rag-in-python-a-simple-guide-6f59590a82c3" target="_blank">1</a></sup> <sup><a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/" target="_blank">2</a></sup> <sup><a href="https://research.ibm.com/blog/retrieval-augmented-generation-RAG" target="_blank">3</a></sup>.   The process was first described in <sup><a href="https://arxiv.org/pdf/2005.11401" target="_blank">4</a></sup>,  The first link states that RAG can be used to update with newer information the answers from an LLM.   An LLM supplies a probabilistic guess on what <i>an</i> answer looks like, hopefully a good answer.   A RAG can also be used for re-ranking the results from the LLM <sup><a href="https://www.datacamp.com/tutorial/boost-llm-accuracy-retrieval-augmented-generation-rag-reranking" target="_blank">5</a></sup>, so the results returned first are best.   The initial LLM result is likely to lack context as the LLM is reporting stored data, the RAG of the users context improves results.   The link lists types of re-rankers.   A high level summary compares RAG to an open book exam <sup><a href="https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2" target="_blank">6</a></sup>.</p>

<p>For a large scale contextual match, it is more efficient to convert the human prompt into a “vector”, or as an optimisation large samples an “embedding” <sup><a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/" target="_blank">7</a></sup>.   This allows efficient transmission of LLM working memory or “conversation knowledge” to local storage or over the network to the LLM server.  However for smaller data sets, RAG can use a traditional DB <sup><a href="https://github.blog/ai-and-ml/generative-ai/what-is-retrieval-augmented-generation-and-what-does-it-do-for-generative-ai/" target="_blank">8</a></sup>, or just search tech (I suspect this needs API access rather than full HTML+JS bells ands whistles).</p>

<p>Used here, Vectors are floats (different to 3d graphics).   <br />
The process to convert a sentence to a couple of numbers is complicated, tightly dialect-specific, and probably off-topic for this article, some notes are <sup><a href="https://wikipedia2vec.github.io/wikipedia2vec/intro/" target="_blank">9</a></sup>.  A review of several “vectoring algorithms” from the perspective of data science.   My brief reading hasn't determined if vectors from different code libraries can be mixed.   There are a couple of “how distant is this word to that word” algorithms, some simple ones are discussed in <sup><a href="https://medium.com/@stepkurniawan/comparing-similarity-searches-distance-metrics-in-vector-stores-rag-model-f0b3f7532d6f" target="_blank">10</a></sup>.   Output of different NLP libraries ~ as defined <sup><a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming" target="_blank">11</a></sup> ~ cannot be merged (just using lang=en, and recent Python).</p>


</div>
<hr />
<div class="lotsOfWords">
<p>Apparently Vector stores are not the same thing as DB (without fiddling with storeproc), as they are described as unstructured heaps <sup><a href="https://medium.com/@mutahar789/optimizing-rag-a-guide-to-choosing-the-right-vector-database-480f71a33139" target="_blank">1</a></sup>.   If your data is an unstructured heap then a traditional SQL DB is not an adjacent idea.  Each typical user journey seems to match best with a different store (same link).   I do not have data on how many floats in <i>answer / content X</i> need to match <i>query Y</i> need to match to make a useful response, but probably more than one.</p>


<h3 class="dontend" id="toc1"> <a href="#toc1" title="Jump to this section." > Value prop <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>
<p>Nearly all recent features or products using an LLM need to include RAG (or similar algorithms) as it reduces occurrences of hallucinations, and it allows visibility on original data source so improving trust in the response <sup><a href="https://www.k2view.com/blog/rag-hallucination/#AI-Hallucination-vs-RAG-Hallucination" target="_blank">2</a></sup>.   This algorithm reflects academic practice in Europe since 800CE (biblio/ references / reading lists).  Some published papers state that training an LLM on data including LLM output leads to generation quality collapse <sup><a href="https://www.nature.com/articles/s41586-024-07566-y" target="_blank">3</a></sup> <sup><a href="https://arxiv.org/abs/2305.17493" target="_blank">4</a></sup> ~ both links are the same work.   Midpoint is the name of an AI image generator, and the response an LLM creates is a most highly likely mid-point. <br />
The features that are most often built with LLM+RAG seem to be <strong>chat bots</strong>.   AI retailers are selling the dream of less staff to respond to customers and potential new customers as a business plan.   For somethings conversational UI are more useful for humans, especially doing low commitment activities ~ eg “Mobile, guess the weather tomorrow”.   It's odd that Siri ~ created and sold by Apple ~  has existed for quite a few years, is a voice prompt for this effect <sup><a href="https://en.wikipedia.org/wiki/Siri" target="_blank">5</a></sup>, but not included in the general OpenAI hype.   <br />
A nice article describing risk areas and mitigation strategies whilst using ML <sup><a href="https://towardsdatascience.com/machine-learning-a-practical-guide-to-managing-risk-52624cf03f3a" target="_blank">6</a></sup>, I would suggest that a similar process is used for LLM+RAG.</p>


<h3 class="dontend" id="toc2"> <a href="#toc2" title="Jump to this section." > Solutions (Python) <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>
<ul class="ulbasic">
    <li>OpenAI is an influential company <a href="https://platform.openai.com/docs/overview" target="_blank">docs</a> <a href="https://platform.openai.com/docs/api-reference/introduction" target="_blank">docs</a> <ul class="ulbasic">
        <li><strong>chatGPTpy</strong>  <a href="https://pypi.org/project/chatgptpy/" target="_blank">pipy</a> <a href="https://github.com/cobinrox/chatgptpy" target="_blank">git</a> (docs in first link)  MIT licence, last update 2022</li>
        <li><strong>ChatGPT-python</strong> <a href="https://pypi.org/project/chatgpt-python/" target="_blank">pipy</a> <a href="https://github.com/dylanmeca/ChatGPT-Python" target="_blank">git</a> (docs in first link) This is desiogned to run on a GPU, is Apache2 licence, and uses Colossal-AI despite name and RLHF, see <sup><a href="https://hpc-ai.com/blog/colossal-ai-chatgpt" target="_blank">7</a></sup></li>
        <li>There are probably more, but general articles <sup><a href="https://medium.com/geekculture/a-simple-guide-to-chatgpt-api-with-python-c147985ae28" target="_blank">8</a></sup> <sup><a href="https://mikulskibartosz.name/chatgpt-api-with-python" target="_blank">9</a></sup></li>
    </ul></li>
    <li><strong>Langchain</strong> <a href="https://github.com/langchain-ai/langchain" target="_blank">git</a> <a href="https://python.langchain.com/v0.2/docs/tutorials/rag/" target="_blank">docs</a> is a wide credited implementation, in Python.  Good composability.  Notes <sup><a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/" target="_blank">10</a></sup> <sup><a href="https://realpython.com/build-llm-rag-chatbot-with-langchain/" target="_blank">11</a></sup> <sup><a href="https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2" target="_blank">12</a></sup> MIT licence</li>
    <li><strong>OpenLLM</strong> ~ a config project to make using other AI software faster and easier. <a href="https://github.com/bentoml/OpenLLM" target="_blank">git</a> <sup><a href="https://docs.bentoml.org/en/v1.1.11/quickstarts/deploy-a-large-language-model-with-openllm-and-bentoml.html" target="_blank">13</a></sup> <sup><a href="https://dev.to/ajeetraina/what-is-openllm-and-what-problem-does-it-solve-5aml" target="_blank">14</a></sup> Runs on GPU, has types and Last update july 2024 (the time of print)</li>
    <li><strong>Cohere</strong> <a href="https://github.com/cohere-ai/cohere-python" target="_blank">git</a> <a href="https://pypi.org/project/cohere/" target="_blank">pipy</a>, MIT licence, and claims it has types.  There is code for every common OS. Last update july 2024 (the time of print)</li>
    <li><strong>RAGchain</strong> <a href="https://github.com/Marker-Inc-Korea/RAGchain" target="_blank">git</a> (this is readonly) <a href="https://pypi.org/project/RAGchain/" target="_blank">pipy</a> <a href="https://nomadamas.gitbook.io/ragchain-docs" target="_blank">docs</a> Uses Apache2 licence </li>
    <li><strong>Scikit-LLM</strong> <a href="https://github.com/iryna-kondr/scikit-llm" target="_blank">git</a> <a href="https://pypi.org/project/scikit-llm/" target="_blank">pipy</a> MIT licence, tagged as OS independent.  </li>
    <li>A detailed discussion on making a fake RAG <sup><a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/" target="_blank">15</a></sup>.  A project to increase performance in RAG, written in Python <sup><a href="https://github.com/RUC-NLPIR/FlashRAG" target="_blank">16</a></sup></li>
    <li>A 'demo with zero code' <a href="https://github.com/mrdbourke/simple-local-rag/tree/main" target="_blank">git</a>, which took me a while to guess the language its written in.   </li>
</ul>


<h3 class="dontend" id="toc3"> <a href="#toc3" title="Jump to this section." > Solutions (JS) <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>
<ul class="ulbasic">
    <li><strong>Embedjs</strong> <a href="https://www.npmjs.com/package/@llm-tools/embedjs" target="_blank">npm</a> <a href="https://github.com/llm-tools/embedJs" target="_blank">git</a> licence: Apache2.  This is a Nodejs framework.</li>
    <li><strong>Langchain</strong> yes same brand in JS <a href="https://github.com/langchain-ai/langchain-nextjs-template" target="_blank">git</a> <a href="https://www.npmjs.com/package/langchain" target="_blank">npm</a>, licence:MIT, Written in TS, has been tested in many JS environments. </li>
</ul>

<p>There is toy implementation of JS running in the browser that does a full LLM on reduced data <a href="https://github.com/mlc-ai/web-llm" target="_blank">git</a> <a href="https://www.npmjs.com/package/@mlc-ai/web-llm" target="_blank">npm</a>.   Also a different implementation  <sup><a href="https://medium.com/@andrewnguonly/local-llm-in-the-browser-powered-by-ollama-236817f335da" target="_blank">17</a></sup>.</p>


</div>
</div>
    </article>
   </main>
	<div id="contentGroup" class="adjacentGroup" data-group="research, engineering" title="Use the first link to get the complete range of the group." > <p>Some similar articles in research </p>
<div id="groupresearch" class="adjacentList"><a class="adjacentItem button" href="/resource/group-XXX?first=research" aria-label="This article lists all items in research group.">All of <br />research<br /> articles </a> <noscript>Seeing this means the Adjacent feature is <strong>disabled</strong><br /> Try the full page link on the left </noscript></div>
<p>Some similar articles in engineering </p>
<div id="groupengineering" class="adjacentList"><a class="adjacentItem button" href="/resource/group-XXX?first=engineering" aria-label="This article lists all items in engineering group.">All of <br />engineering<br /> articles </a> <noscript>Seeing this means the Adjacent feature is <strong>disabled</strong><br /> Try the full page link on the left </noscript></div>
 </div>

  </div>
  <fieldset class="outer_menu articleHeader">
	<legend></legend>
	<nav>
		<div id="navBar" class="row">
			<div class="column">
				<div class="top-bar fullWidth">
					<header><h1>AI RAG: Retrieval Augmented Generation</h1></header>
			    	<p role="status" class="bigScreenOnly">    </p>
				</div>
				<div id="shareGroup" class="bibbles row addReading">
					<span class="allButtons"> 
						<a id="siteChartLink" class="button smallScreenOnly" href="/resource/site-chart" title="open a webpage of what articles this site holds.">Sitemap</a>
						<a id="rssLink" href="https://owenberesford.me.uk/resource/rss" title="Access the sites RSS feed."> <i class="fa fa-rss" aria-label="Open the RSS for this site." aria-hidden="true"></i><span class="sr-only">RSS</span></a> 
						<span class="button smallScreenOnly" id="shareMenuTrigger" rel="nofollow"> Share </span>
						<span class="bigScreenOnly">Share: </span>
                        <a href="https://twitter.com/intent/tweet?text=I+think+this+is+important+https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-retrieval-augmented-generation" title="Share this resource on your twitter account." target="_blank" class="bigScreenOnly"> <i class="fa fa-twitter" aria-label="Share this resource on your twitter account." aria-hidden="true"><span class="sr-only">Twitter</span> </i></a>
						<a href="#" id="mastoTrigger" class="masto bigScreenOnly" title="Share this article with *your* mastodon instance" >	<i class="fa fa-mastodon" aria-label="Share this article on *your* mastodon instance." aria-hidden="true"></i>><span class="sr-only">Mastodon</span> </a>

						<a href="https://www.reddit.com/submit?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-retrieval-augmented-generation" target="_blank" title="Share this article with your Reddit audience" class="bigScreenOnly" ><i aria-label="Share this article with your Reddit audience." class="fa fa-reddit-square" aria-hidden="true"></i><span class="sr-only">Reddit </span> </a>
						<a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-retrieval-augmented-generation" target="_blank" class="bigScreenOnly" title="Share current article with your linked-in audience." ><i class="fa fa-linkedin-square" aria-hidden="true" aria-label="Share this article with your linked-in audience."></i><span class="sr-only">Linkedin</span> </a>
						<a title="Share current article with Hacker news/ Y combinator audience" target="_blank" class="bigScreenOnly" href="http://news.ycombinator.com/submitlink?u=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-retrieval-augmented-generation&amp;t=AI+RAG+coding"> <i class="fa fa-hacker-news" aria-label="Share this article with your Y combinator audience." aria-hidden="true"> </i><span class="sr-only">Hacker new</span> </a>

						<a title="Share this article with your Xing audience." href="https://www.xing.com/spi/shares/new?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-retrieval-augmented-generation" target="_blank" class="bigScreenOnly" ><i class="fa fa-xing-square" aria-hidden="true" aria-label="Share this article with your Xing audience."></i><span class="sr-only">Xing</span> </a>
					</span>

					<span class="ultraSkinny bigScreenOnly"> 
						<span>Edited <time datetime="2024-08-14T20:47:19">14th of Aug 2024</time>
						</span>
						<span>Created <time datetime="2024-07-23T00:00:00" title="If the value says 03-03-2015; its wrong but that is when this project was moved to the current git project" >23rd of Jul 2024</time> </span>
					</span>

				</div>
			</div>
			<dialog id="popup" class="popup1 bigScreenOnly">
				<form method="dialog" encoding="multipart/form-data" action="." name="mastoSelection"  >
					<label for="mastodonserver">your server: 
						<input id="mastodonserver" max-length="50" data-url="https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-retrieval-augmented-generation" type="text" value="" placeholder="mastodon.social" />  
					</label> 
					<span id="sendMasto" class="button masto" href="#" title="Share article to *your* mastodon server">Share article now</span>
					<span class="button trimmed" id="hideMasto" href="#" title="Close popup"> <i class="fa fa-cancel" aria-hidden="true"></i> Cancel </span>
				</form>
			</dialog>

<fieldset class="h4_menu column bigScreenOnly ">
<legend><span id="pageMenu"><i class="fa fa-ob1burger" aria-hidden="true"></i><span class="sr-only">Menu</span> </span></legend>
<menu class="h4_lean">
<li class="h4_odd"><a href="#toc0">Theory / maths</a></li>
<li><a href="#toc1">Value prop</a></li>
<li class="h4_odd"><a href="#toc2">Solutions (Python)</a></li>
<li><a href="#toc3">Solutions (JS)</a></li>
</menu>
<br />

</fieldset>
	</div>
<menu class="burgerMenu" >
<li class="h4_odd">Additional features</li>
<li class=""><a href="/resource/home"><i class="fa fa-angle-left" aria-hidden="true"></i> Home</a> </li> 
<li class="h4_odd"><a href="/resource/search">Search <i class="fa fa-angle-right" aria-hidden="true"></i></a></li>
<li class=""><a href="/resource/appearance">Appearance <i class="fa fa-angle-right" aria-hidden="true"></i></a></li>
<li class="h4_odd"><a href="/resource/contact-me">Contact me <i class="fa fa-angle-right" aria-hidden="true"></i></a></li>
<li class=""><a href="#contentGroup">Similar articles</a></li>
</menu>
	</nav>
</fieldset>
		</div>
 <br class="blocker" />
 <div id="biblio" style="display:none;">
    <br class="blocker" />
 </div>
 
 <footer>
  <div class="h4_footer"> 
	<div class="leftFooter"> 
		<a href="https://www.plainenglish.co.uk/services.html" target="_blank" title="They, er, don't have a service for >200,000 word sites, so no logo.">Campaign for Plain English</a><br />
		My profile: <a href="https://www.linkedin.com/in/owen-beresford-bb6ab030/" target="_blank" aria-label="my linked-in" title="Load my linked-in profile" ><i class="fixLinkedSq fa fa-linkedin-square" aria-hidden="true" aria-label="Open my linked in profile" ></i><span class="sr-only">linkedin</span></a>  
	</div> 
	<p> Page rendered <time datetime="2024-08-14T20:47:52">14th of Aug 2024, 20:47:52</time>, Copyright &copy; 2022 Owen Beresford, <a href="https://owenberesford.me.uk/resource/contact-me">contact me</a>.  Last modified <time datetime="2024-08-14T20:47:19">14th of Aug 2024</time>.
    <p>Read the generous <a rel="license" href="https://owenberesford.me.uk/resource/licence" title="Load the license term; but not that interesting">licence terms</a>, if you feel the need, there is a <a href="https://owenberesford.me.uk/resource/privacy#" title="Load the privacy terms" >privacy here</a>.    View the <a href="https://owenberesford.me.uk/resource/site-chart#" title="Load a page showing all the articles on this site">site map</a>.  <a href="#pageMenu">Jump to menu</a>
</div>
</footer>
<script defer type="module" src="/asset/ob1-202406.min.mjs" ></script>

</body>
</html>